{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98841380",
   "metadata": {},
   "source": [
    "# Prediksi Risiko Stroke\n",
    "\n",
    "### Nama    : [Raka Warnandi]\n",
    "### NIM     : [A11.2023.15383]\n",
    "----------------------------------------------------------------\n",
    "### Ringkasan/Permasalahan Project dan Tujuan yang Akan Dicapai\n",
    "#### Permasalahan: \n",
    "Dataset ini berisi data demografis dan kesehatan dari ribuan pasien. Stroke merupakan penyebab kematian dan kecacatan yang serius, dan prediksi dini sangat penting. Tantangannya adalah membangun model yang dapat mengidentifikasi individu dengan risiko tinggi terkena stroke berdasarkan atribut seperti usia, riwayat penyakit (hipertensi, penyakit jantung), gaya hidup (merokok), dan data klinis (kadar glukosa, BMI). Dataset ini juga memiliki tantangan ketidakseimbangan kelas (class imbalance), di mana jumlah pasien yang mengalami stroke jauh lebih sedikit daripada yang tidak.\n",
    "\n",
    "#### Tujuan: \n",
    "Membangun dan mengevaluasi beberapa model klasifikasi (seperti Logistic Regression, Random Forest, dan XGBoost) untuk memprediksi kemungkinan seseorang mengalami stroke. Tujuan utamanya adalah menciptakan model yang tidak hanya akurat secara keseluruhan tetapi juga memiliki performa baik dalam mendeteksi kasus stroke (kelas minoritas), yang akan diukur menggunakan metrik seperti F1-Score dan AUC-ROC. Model ini berpotensi menjadi alat bantu skrining awal bagi tenaga medis.\n",
    "\n",
    "----------------------------------------------------------------\n",
    "### Dataset: Kaggle Stroke Prediction Dataset\n",
    "- **Sumber**: [Kaggle Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset)\n",
    "- **Total Data**: 5110 sampel\n",
    "- **Fitur**: 11 fitur (numerik dan kategorikal), tidak termasuk ID\n",
    "- **Target**: `stroke` (1: ya, 0: tidak)\n",
    "\n",
    "### Kategori Fitur:\n",
    "1. **Demografis**: `gender`, `age`, `ever_married`, `Residence_type`\n",
    "2. **Riwayat Medis**: `hypertension`, `heart_disease`\n",
    "3. **Gaya Hidup**: `work_type`, `smoking_status`\n",
    "4. **Data Klinis**: `avg_glucose_level`, `bmi`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a53a16",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '\"c:/Users/RAKA W/AppData/Local/Programs/Python/Python313/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Import library dasar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import library untuk preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Import algoritma machine learning (Klasifikasi)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "# Import untuk evaluasi model (Klasifikasi)\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Setting untuk visualisasi\n",
    "# Menggunakan style yang kompatibel dengan versi Matplotlib yang lebih baru\n",
    "plt.style.use('seaborn-v0_8-whitegrid') \n",
    "sns.set_palette(\"viridis\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Semua library berhasil diimpor!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d13f267",
   "metadata": {},
   "source": [
    "## 2. Membaca Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b7a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset dari path lokal\n",
    "file_path = \"dataset/healthcare-dataset-stroke-data.csv\"\n",
    "\n",
    "print(\"üì• Loading dataset dari path lokal...\")\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(file_path)\n",
    "print(f\"‚úÖ Data loaded: {df.shape}\")\n",
    "\n",
    "print(f\"\\nüìä Dataset: Stroke Prediction Dataset\")\n",
    "print(f\"üè† Total samples: {len(df):,}\")\n",
    "print(f\"üìã Total fitur: {len(df.columns)} (termasuk ID)\")\n",
    "print(f\"üéØ Target: stroke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9a89f6",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b09f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informasi dasar dataset\n",
    "print(\"=== INFORMASI DASAR DATASET ===\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\n=== STATISTIK DESKRIPTIF (FITUR NUMERIK) ===\")\n",
    "display(df.describe())\n",
    "\n",
    "print(\"\\n=== JUMLAH NILAI KOSONG ===\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview data\n",
    "print(\"=== PREVIEW DATA ===\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d706f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis target variable (stroke)\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.countplot(x='stroke', data=df)\n",
    "plt.title('Distribusi Target Variable (Stroke)')\n",
    "plt.xlabel('Mengalami Stroke (1: Ya, 0: Tidak)')\n",
    "plt.ylabel('Jumlah Pasien')\n",
    "plt.xticks([0, 1], ['Tidak', 'Ya'])\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}\\n({p.get_height()/len(df)*100:.1f}%)',\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'center', \n",
    "                xytext = (0, 9),\n",
    "                textcoords = 'offset points')\n",
    "plt.show()\n",
    "\n",
    "print(\"Insight: Dataset sangat tidak seimbang (imbalanced), dengan hanya 4.9% kasus stroke. Ini perlu ditangani dalam preprocessing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ed771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis fitur penting\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Distribusi Usia vs Stroke\n",
    "sns.histplot(data=df, x='age', hue='stroke', multiple='stack', ax=axes[0, 0], bins=30)\n",
    "axes[0, 0].set_title('Distribusi Usia berdasarkan Status Stroke')\n",
    "\n",
    "# 2. Hubungan Hipertensi & Penyakit Jantung dengan Stroke\n",
    "df_hyper_heart = df.melt(id_vars=['stroke'], value_vars=['hypertension', 'heart_disease'], var_name='Kondisi')\n",
    "sns.countplot(data=df_hyper_heart, x='Kondisi', hue='stroke', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Riwayat Hipertensi & Penyakit Jantung vs Stroke')\n",
    "axes[0, 1].set_xticklabels(['Hipertensi', 'Penyakit Jantung'])\n",
    "\n",
    "# 3. Rata-rata Kadar Glukosa vs Stroke\n",
    "sns.boxplot(data=df, x='stroke', y='avg_glucose_level', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Kadar Glukosa vs Stroke')\n",
    "axes[1, 0].set_xticklabels(['Tidak', 'Ya'])\n",
    "\n",
    "# 4. Status Merokok vs Stroke\n",
    "sns.countplot(data=df, x='smoking_status', hue='stroke', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Status Merokok vs Stroke')\n",
    "axes[1, 1].tick_params(axis='x', rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9695c1",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Drop kolom ID karena tidak relevan\n",
    "df = df.drop('id', axis=1)\n",
    "print(\"Kolom 'id' dihapus.\")\n",
    "\n",
    "# 2. Handle missing values (BMI)\n",
    "df['bmi'] = pd.to_numeric(df['bmi'], errors='coerce')\n",
    "bmi_median = df['bmi'].median()\n",
    "df['bmi'].fillna(bmi_median, inplace=True)\n",
    "print(f\"Missing values di 'bmi' diisi dengan median: {bmi_median:.2f}\")\n",
    "\n",
    "# 3. Handle 'Other' gender (hanya ada 1 sampel)\n",
    "df = df[df['gender'] != 'Other']\n",
    "print(\"Sampel dengan gender 'Other' dihapus.\")\n",
    "\n",
    "# 4. Encoding fitur kategorikal\n",
    "categorical_cols = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
    "print(\"Fitur kategorikal di-encode menggunakan One-Hot Encoding.\")\n",
    "\n",
    "# 5. Pisahkan fitur (X) dan target (y)\n",
    "X = df_encoded.drop('stroke', axis=1)\n",
    "y = df_encoded['stroke']\n",
    "\n",
    "# 6. Split data menjadi training dan testing set (80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"Data dibagi menjadi training dan testing set.\")\n",
    "\n",
    "# 7. Feature Scaling (hanya pada fitur numerik)\n",
    "numerical_cols = ['age', 'avg_glucose_level', 'bmi']\n",
    "scaler = StandardScaler()\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "print(\"Fitur numerik di-scaling menggunakan StandardScaler.\")\n",
    "\n",
    "# 8. Handle class imbalance dengan SMOTE (hanya pada data training)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "print(\"Class imbalance pada data training ditangani dengan SMOTE.\")\n",
    "\n",
    "print(\"\\n‚úÖ Data preprocessing selesai!\")\n",
    "print(f\"Shape X_train original: {X_train.shape}\")\n",
    "print(f\"Shape X_train resampled: {X_train_resampled.shape}\")\n",
    "print(f\"Distribusi target di training set setelah SMOTE:\\n{y_train_resampled.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d53fff",
   "metadata": {},
   "source": [
    "## 5. Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b18ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inisialisasi model\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "    'SVC': SVC(probability=True, random_state=42)\n",
    "}\n",
    "\n",
    "# Dictionary untuk menyimpan hasil\n",
    "results = {}\n",
    "\n",
    "print(\"=== TRAINING MODELS ===\")\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name}...\", end=\" \")\n",
    "    \n",
    "    # Training model pada data yang sudah di-resample\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    # Prediksi pada test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Hitung metrik evaluasi\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'F1-Score (1)': report['1']['f1-score'],\n",
    "        'AUC': auc,\n",
    "        'Model': model\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ F1-Score: {report['1']['f1-score']:.4f}\")\n",
    "\n",
    "print(\"\\nüéâ Training selesai!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172710f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi dan ranking model\n",
    "results_df = pd.DataFrame({k: {metric: v[metric] for metric in ['Accuracy', 'F1-Score (1)', 'AUC']} for k, v in results.items()}).T\n",
    "results_df = results_df.sort_values('F1-Score (1)', ascending=False)\n",
    "\n",
    "print(\"=== HASIL EVALUASI MODEL ===\")\n",
    "print(f\"{'Rank':<4} {'Model':<20} {'Accuracy':<10} {'F1-Score (1)':<15} {'AUC':<8}\")\n",
    "print(\"-\" * 68)\n",
    "\n",
    "for i, (model_name, row) in enumerate(results_df.iterrows(), 1):\n",
    "    print(f\"{i:<4} {model_name:<20} {row['Accuracy']:.4f}     {row['F1-Score (1)']:.4f}         {row['AUC']:.4f}\")\n",
    "\n",
    "# Model terbaik\n",
    "best_model_name = results_df.index[0]\n",
    "best_f1 = results_df.loc[best_model_name, 'F1-Score (1)']\n",
    "best_auc = results_df.loc[best_model_name, 'AUC']\n",
    "\n",
    "print(f\"\\nüèÜ MODEL TERBAIK: {best_model_name}\")\n",
    "print(f\"üìä F1-Score (Stroke): {best_f1:.4f}\")\n",
    "print(f\"üìä AUC Score: {best_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3feeb00",
   "metadata": {},
   "source": [
    "## 6. Comprehensive Visualization & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db13988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi komprehensif hasil\n",
    "top_4_models = results_df.head(4).index\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# 1. Confusion Matrix untuk 4 model terbaik\n",
    "for i, model_name in enumerate(top_4_models):\n",
    "    model = results[model_name]['Model']\n",
    "    y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
    "                xticklabels=['Tidak Stroke', 'Stroke'],\n",
    "                yticklabels=['Tidak Stroke', 'Stroke'])\n",
    "    axes[i].set_title(f'Confusion Matrix - {model_name}')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    axes[i].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f20f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Kurva ROC untuk semua model\n",
    "plt.figure(figsize=(12, 8))\n",
    "for name, res in results.items():\n",
    "    model = res['Model']\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    auc = res['AUC']\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'r--', label='Random Chance')\n",
    "plt.title('Kurva ROC untuk Semua Model')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d6b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Importance dari model terbaik (jika tree-based) atau Koefisien (jika linear)\n",
    "best_model = results[best_model_name]['Model']\n",
    "\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_imp = pd.DataFrame(sorted(zip(best_model.feature_importances_, X.columns)), columns=['Importance', 'Feature'])\n",
    "elif hasattr(best_model, 'coef_'):\n",
    "    feature_imp = pd.DataFrame({'Feature': X.columns, 'Importance': np.abs(best_model.coef_[0])}).sort_values('Importance', ascending=True)\n",
    "else:\n",
    "    feature_imp = None\n",
    "\n",
    "if feature_imp is not None:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(feature_imp['Feature'], feature_imp['Importance'], color='teal')\n",
    "    plt.title(f'Feature Importance - {best_model_name}')\n",
    "    plt.xlabel('Importance/Coefficient Magnitude')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"=== TOP 5 FITUR PENTING - {best_model_name} ===\")\n",
    "    display(feature_imp.sort_values(by='Importance', ascending=False).head())\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Model terbaik ({best_model_name}) tidak memiliki atribut 'feature_importances_' atau 'coef_'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea50c59",
   "metadata": {},
   "source": [
    "## 7. Kesimpulan dan Rekomendasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6d760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kesimpulan\n",
    "best_model_info = results[best_model_name]\n",
    "y_pred_best = best_model_info['Model'].predict(X_test)\n",
    "cm_best = confusion_matrix(y_test, y_pred_best)\n",
    "tn, fp, fn, tp = cm_best.ravel()\n",
    "\n",
    "print(\"=== KESIMPULAN AKHIR ===\")\n",
    "print(f\"Project ini berhasil membangun dan mengevaluasi beberapa model machine learning untuk memprediksi risiko stroke. Tantangan utama, yaitu ketidakseimbangan kelas, telah ditangani menggunakan teknik oversampling SMOTE.\")\n",
    "print(f\"\\nüèÜ Model dengan performa terbaik pada test set adalah **{best_model_name}**.\")\n",
    "print(\"--------------------------------------------------------------------------\")\n",
    "print(f\"üìä Metrik Kunci:\")\n",
    "print(f\"  - **AUC Score**: {best_auc:.4f}, menunjukkan kemampuan model yang baik dalam membedakan antara pasien berisiko dan tidak berisiko.\")\n",
    "print(f\"  - **F1-Score (kelas Stroke)**: {best_f1:.4f}, mengindikasikan keseimbangan yang baik antara presisi dan recall untuk mendeteksi kasus stroke.\")\n",
    "print(f\"  - **Akurasi**: {best_model_info['Accuracy']:.4f}, performa keseluruhan model.\")\n",
    "\n",
    "print(f\"\\nüß† Analisis Prediksi:\")\n",
    "print(f\"  - Dari {tp+fn} kasus stroke aktual di test set, model berhasil mendeteksi **{tp}** kasus (True Positives).\")\n",
    "print(f\"  - Namun, model masih melewatkan **{fn}** kasus stroke (False Negatives), yang merupakan area kritis untuk perbaikan di masa depan.\")\n",
    "print(f\"  - Model salah mengklasifikasikan **{fp}** pasien sehat sebagai berisiko stroke (False Positives).\")\n",
    "\n",
    "print(\"\\nüîë Fitur Paling Berpengaruh (berdasarkan model terbaik):\")\n",
    "if feature_imp is not None:\n",
    "    top_feature_list = feature_imp.sort_values(by='Importance', ascending=False)['Feature'].head(3).tolist()\n",
    "    print(f\"  - Fitur seperti **{', '.join(top_feature_list)}** terbukti menjadi prediktor paling kuat.\")\n",
    "else:\n",
    "    print(\"  - Analisis feature importance tidak tersedia untuk model ini.\")\n",
    "\n",
    "print(\"\\nüöÄ Rekomendasi Selanjutnya:\")\n",
    "print(\"  1. **Hyperparameter Tuning**: Lakukan tuning lebih dalam pada model terbaik (misalnya dengan GridSearchCV atau RandomizedSearchCV) untuk mengoptimalkan performa.\")\n",
    "print(\"  2. **Pengumpulan Data**: Menambah jumlah data, terutama untuk kelas minoritas (stroke), akan sangat meningkatkan kualitas model.\")\n",
    "print(\"  3. **Ensemble Methods**: Menggabungkan prediksi dari beberapa model terbaik untuk menciptakan model yang lebih robust.\")\n",
    "print(\"  4. **Interpretasi Model**: Gunakan teknik seperti SHAP (SHapley Additive exPlanations) untuk memahami bagaimana setiap fitur mempengaruhi prediksi secara individual.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
